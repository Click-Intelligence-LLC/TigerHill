#!/usr/bin/env python3
"""
åˆ†æGemini CLIå¤šè½®å¯¹è¯æ•è·æ•°æ®
"""

import json
import glob
import os
from datetime import datetime
from collections import defaultdict

def analyze_session_file(filepath):
    """åˆ†æå•ä¸ªä¼šè¯æ–‡ä»¶"""
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)

    session_info = {
        'file': os.path.basename(filepath),
        'session_id': data.get('session_id', 'unknown'),
        'start_time': data.get('start_time'),
        'tool': data.get('metadata', {}).get('tool', 'unknown'),
        'total_turns': len(data.get('turns', [])),
        'processes': data.get('metadata', {}).get('processes', []),
        'turns': []
    }

    # åˆ†ææ¯ä¸ªturn
    for turn_idx, turn in enumerate(data.get('turns', []), 1):
        turn_info = {
            'turn_number': turn_idx,
            'conversation_length': turn.get('conversation_length', 0),
            'timestamp': turn.get('timestamp'),
            'requests': [],
            'responses': [],
            'statistics': {}
        }

        # åˆ†æè¯·æ±‚
        for req in turn.get('requests', []):
            if req.get('type') == 'gemini_request':
                request_data = req.get('data', {})
                contents = request_data.get('contents', [])

                # æå–ç”¨æˆ·è¾“å…¥
                user_input = None
                for content in contents:
                    if content.get('role') == 'user':
                        parts = content.get('parts', [])
                        if parts and 'text' in parts[0]:
                            user_input = parts[0]['text']
                            break

                # æå–ç³»ç»ŸæŒ‡ä»¤
                system_instruction = request_data.get('systemInstruction', {})
                system_text = None
                if system_instruction:
                    parts = system_instruction.get('parts', [])
                    if parts and 'text' in parts[0]:
                        system_text = parts[0]['text']

                turn_info['requests'].append({
                    'user_input': user_input,
                    'system_instruction_length': len(system_text) if system_text else 0,
                    'model': request_data.get('model'),
                    'timestamp': req.get('timestamp')
                })

        # åˆ†æå“åº”
        for resp in turn.get('responses', []):
            if resp.get('type') == 'gemini_response':
                response_data = resp.get('data', {})
                candidates = response_data.get('candidates', [])

                response_text = None
                if candidates:
                    content = candidates[0].get('content', {})
                    parts = content.get('parts', [])
                    if parts and 'text' in parts[0]:
                        response_text = parts[0]['text']

                # Tokenä½¿ç”¨ç»Ÿè®¡
                usage = response_data.get('usageMetadata', {})

                turn_info['responses'].append({
                    'text_length': len(response_text) if response_text else 0,
                    'text_preview': response_text[:200] if response_text else None,
                    'prompt_tokens': usage.get('promptTokenCount', 0),
                    'candidates_tokens': usage.get('candidatesTokenCount', 0),
                    'total_tokens': usage.get('totalTokenCount', 0),
                    'timestamp': resp.get('timestamp')
                })

                turn_info['statistics'] = {
                    'prompt_tokens': usage.get('promptTokenCount', 0),
                    'completion_tokens': usage.get('candidatesTokenCount', 0),
                    'total_tokens': usage.get('totalTokenCount', 0)
                }

        session_info['turns'].append(turn_info)

    return session_info

def calculate_overall_statistics(sessions):
    """è®¡ç®—æ€»ä½“ç»Ÿè®¡"""
    stats = {
        'total_sessions': len(sessions),
        'total_turns': 0,
        'total_tokens': 0,
        'total_prompt_tokens': 0,
        'total_completion_tokens': 0,
        'avg_tokens_per_turn': 0,
        'avg_response_length': 0,
        'total_response_chars': 0
    }

    turn_count = 0
    response_lengths = []

    for session in sessions:
        stats['total_turns'] += len(session['turns'])
        for turn in session['turns']:
            turn_count += 1
            if turn['statistics']:
                stats['total_tokens'] += turn['statistics'].get('total_tokens', 0)
                stats['total_prompt_tokens'] += turn['statistics'].get('prompt_tokens', 0)
                stats['total_completion_tokens'] += turn['statistics'].get('completion_tokens', 0)

            for resp in turn['responses']:
                if resp['text_length']:
                    response_lengths.append(resp['text_length'])
                    stats['total_response_chars'] += resp['text_length']

    if turn_count > 0:
        stats['avg_tokens_per_turn'] = stats['total_tokens'] / turn_count

    if response_lengths:
        stats['avg_response_length'] = sum(response_lengths) / len(response_lengths)

    return stats

def print_analysis(sessions, overall_stats):
    """æ‰“å°åˆ†æç»“æœ"""
    print("=" * 80)
    print("  TigerHill å¤šè½®å¯¹è¯åˆ†ææŠ¥å‘Š")
    print("=" * 80)
    print()

    print("ğŸ“Š æ€»ä½“ç»Ÿè®¡")
    print("-" * 80)
    print(f"æ€»ä¼šè¯æ•°: {overall_stats['total_sessions']}")
    print(f"æ€»è½®æ¬¡æ•°: {overall_stats['total_turns']}")
    print(f"æ€» Token æ•°: {overall_stats['total_tokens']:,}")
    print(f"  - Prompt Tokens: {overall_stats['total_prompt_tokens']:,}")
    print(f"  - Completion Tokens: {overall_stats['total_completion_tokens']:,}")
    print(f"å¹³å‡æ¯è½® Tokens: {overall_stats['avg_tokens_per_turn']:.1f}")
    print(f"å¹³å‡å“åº”é•¿åº¦: {overall_stats['avg_response_length']:.0f} å­—ç¬¦")
    print(f"æ€»å“åº”å­—ç¬¦æ•°: {overall_stats['total_response_chars']:,}")
    print()

    # ä¼°ç®—æˆæœ¬ï¼ˆåŸºäºGemini Proå®šä»·ï¼‰
    # Gemini Pro: $0.00025 per 1K prompt tokens, $0.0005 per 1K completion tokens
    prompt_cost = (overall_stats['total_prompt_tokens'] / 1000) * 0.00025
    completion_cost = (overall_stats['total_completion_tokens'] / 1000) * 0.0005
    total_cost = prompt_cost + completion_cost

    print("ğŸ’° æˆæœ¬ä¼°ç®— (Gemini Pro å®šä»·)")
    print("-" * 80)
    print(f"Prompt æˆæœ¬: ${prompt_cost:.6f}")
    print(f"Completion æˆæœ¬: ${completion_cost:.6f}")
    print(f"æ€»æˆæœ¬: ${total_cost:.6f}")
    print()

    # æŒ‰ä¼šè¯è¯¦ç»†åˆ†æ
    print("ğŸ“ å„è½®æ¬¡è¯¦ç»†åˆ†æ")
    print("=" * 80)
    print()

    for idx, session in enumerate(sessions, 1):
        print(f"ä¼šè¯ {idx}/{len(sessions)}")
        print(f"Session ID: {session['session_id'][:30]}...")
        print(f"æ–‡ä»¶: {session['file']}")
        print(f"è½®æ¬¡æ•°: {session['total_turns']}")
        print()

        for turn in session['turns']:
            print(f"  â”Œâ”€ Turn {turn['turn_number']}")
            print(f"  â”‚")

            # ç”¨æˆ·è¾“å…¥
            for req in turn['requests']:
                if req['user_input']:
                    input_preview = req['user_input'][:100].replace('\n', ' ')
                    print(f"  â”‚ ğŸ‘¤ ç”¨æˆ·è¾“å…¥: {input_preview}...")
                    if req['system_instruction_length']:
                        print(f"  â”‚    ç³»ç»ŸæŒ‡ä»¤é•¿åº¦: {req['system_instruction_length']} å­—ç¬¦")

            # AIå“åº”
            for resp in turn['responses']:
                if resp['text_preview']:
                    preview = resp['text_preview'][:100].replace('\n', ' ')
                    print(f"  â”‚ ğŸ¤– AIå“åº”: {preview}...")
                    print(f"  â”‚    å“åº”é•¿åº¦: {resp['text_length']} å­—ç¬¦")
                    print(f"  â”‚    Tokens: {resp['total_tokens']} (æç¤º: {resp['prompt_tokens']}, å®Œæˆ: {resp['candidates_tokens']})")

            print(f"  â”‚")

        print(f"  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        print()

    print("=" * 80)
    print("åˆ†æå®Œæˆï¼")
    print("=" * 80)

def main():
    capture_dir = "/Users/yinaruto/MyProjects/ChatLLM/TigerHill/prompt_captures/multiturn_test"

    # æŸ¥æ‰¾æ‰€æœ‰ä¼šè¯æ–‡ä»¶
    session_files = sorted(glob.glob(f"{capture_dir}/session_*.json"))

    if not session_files:
        print("âŒ æœªæ‰¾åˆ°ä¼šè¯æ–‡ä»¶")
        return

    print(f"æ‰¾åˆ° {len(session_files)} ä¸ªä¼šè¯æ–‡ä»¶")
    print()

    # åˆ†ææ‰€æœ‰ä¼šè¯
    sessions = []
    for filepath in session_files:
        try:
            session_info = analyze_session_file(filepath)
            sessions.append(session_info)
        except Exception as e:
            print(f"âš ï¸  åˆ†ææ–‡ä»¶å¤±è´¥: {filepath}")
            print(f"   é”™è¯¯: {e}")
            continue

    # è®¡ç®—æ€»ä½“ç»Ÿè®¡
    overall_stats = calculate_overall_statistics(sessions)

    # æ‰“å°åˆ†æç»“æœ
    print_analysis(sessions, overall_stats)

    # ä¿å­˜åˆ†ææŠ¥å‘Š
    report_file = f"{capture_dir}/analysis_report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump({
            'sessions': sessions,
            'overall_statistics': overall_stats,
            'generated_at': datetime.now().isoformat()
        }, f, indent=2, ensure_ascii=False)

    print()
    print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

if __name__ == "__main__":
    main()
