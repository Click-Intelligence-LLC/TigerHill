# LLM Function Calling Testing Template
# Tests LLM function calling / tool use capabilities

metadata:
  name: "llm-function-calling"
  display_name: "LLM Function Calling Testing"
  description: "Test LLM function calling with tool definitions and execution validation"
  category: "llm"
  version: "1.0.0"
  author: "TigerHill"
  tags: ["llm", "function-calling", "tools", "agents"]

parameters:
  - name: "agent_name"
    display_name: "Agent Name"
    description: "Name for the test agent"
    type: "string"
    required: true
    default: "my-function-agent"
    validation:
      pattern: "^[a-zA-Z0-9_-]+$"

  - name: "model_name"
    display_name: "Model Name"
    description: "LLM model to test (must support function calling)"
    type: "choice"
    required: true
    default: "gpt-4"
    choices: ["gpt-4", "gpt-3.5-turbo", "claude-3-opus", "claude-3-sonnet"]

  - name: "num_tools"
    display_name: "Number of Tools"
    description: "Number of tool definitions to provide"
    type: "integer"
    required: true
    default: 3
    validation:
      min: 1
      max: 10

  - name: "validate_tool_calls"
    display_name: "Validate Tool Calls"
    description: "Validate that model makes appropriate tool calls"
    type: "boolean"
    required: true
    default: true

dependencies:
  pip:
    - "pytest>=7.4.0"
    - "openai>=1.0.0"

files:
  - path: "test_{{agent_name}}.py"
    template: "main_script"
  - path: "requirements.txt"
    template: "requirements"
  - path: "README.md"
    template: "readme"

templates:
  main_script: |
    #!/usr/bin/env python3
    """
    {{ metadata.display_name }} - Generated by TigerHill

    {{ metadata.description }}
    """

    import pytest
    import json
    from tigerhill.storage.trace_store import TraceStore, EventType


    class Test{{ agent_name | camel_case }}:
        """{{ metadata.display_name }} Test Suite"""

        @pytest.fixture
        def trace_store(self, tmp_path):
            """Create trace store for recording"""
            return TraceStore(storage_path=str(tmp_path))

        @pytest.fixture
        def tool_definitions(self):
            """Define tools for the LLM"""
            tools = [
                {
                    "type": "function",
                    "function": {
                        "name": "get_weather",
                        "description": "Get current weather for a location",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "location": {
                                    "type": "string",
                                    "description": "City and state, e.g. San Francisco, CA"
                                },
                                "unit": {
                                    "type": "string",
                                    "enum": ["celsius", "fahrenheit"],
                                    "description": "Temperature unit"
                                }
                            },
                            "required": ["location"]
                        }
                    }
                },
                {
                    "type": "function",
                    "function": {
                        "name": "calculate",
                        "description": "Perform mathematical calculations",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "expression": {
                                    "type": "string",
                                    "description": "Mathematical expression to evaluate"
                                }
                            },
                            "required": ["expression"]
                        }
                    }
                },
                {
                    "type": "function",
                    "function": {
                        "name": "search",
                        "description": "Search for information",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "query": {
                                    "type": "string",
                                    "description": "Search query"
                                }
                            },
                            "required": ["query"]
                        }
                    }
                }
            ]
            return tools[:{{ num_tools }}]

        def test_{{ agent_name | snake_case }}(self, tool_definitions, trace_store):
            """Test {{ metadata.display_name }}"""

            # Start trace
            trace_id = trace_store.start_trace(
                agent_name="{{ agent_name }}",
                task_id="function-calling-test",
                metadata={
                    "model": "{{ model_name }}",
                    "num_tools": {{ num_tools }}
                }
            )

            try:
                # Record tool definitions
                trace_store.write_event(
                    {
                        "type": "tools_registered",
                        "tools": tool_definitions,
                        "count": len(tool_definitions)
                    },
                    trace_id=trace_id
                )

                # Simulate prompt that should trigger tool use
                prompt = "What's the weather in San Francisco?"

                trace_store.write_event(
                    {
                        "type": "prompt",
                        "content": prompt,
                        "model": "{{ model_name }}",
                        "tools_available": [t["function"]["name"] for t in tool_definitions]
                    },
                    trace_id=trace_id,
                    event_type=EventType.PROMPT
                )

                # TODO: Replace with actual LLM API call with tools
                # For demonstration, simulate a tool call
                simulated_tool_call = {
                    "id": "call_1",
                    "type": "function",
                    "function": {
                        "name": "get_weather",
                        "arguments": json.dumps({
                            "location": "San Francisco, CA",
                            "unit": "fahrenheit"
                        })
                    }
                }

                # Record tool call
                trace_store.write_event(
                    {
                        "type": "tool_call",
                        "tool_call_id": simulated_tool_call["id"],
                        "function_name": simulated_tool_call["function"]["name"],
                        "arguments": simulated_tool_call["function"]["arguments"]
                    },
                    trace_id=trace_id,
                    event_type=EventType.TOOL_CALL
                )

                {% if validate_tool_calls -%}
                # Validate tool call
                assert simulated_tool_call["function"]["name"] == "get_weather", \
                    "Expected get_weather tool to be called"

                args = json.loads(simulated_tool_call["function"]["arguments"])
                assert "location" in args, "Tool call should include location parameter"
                {% endif -%}

                # Simulate tool execution result
                tool_result = {
                    "temperature": 72,
                    "conditions": "Sunny",
                    "location": "San Francisco, CA"
                }

                # Record tool result
                trace_store.write_event(
                    {
                        "type": "tool_result",
                        "tool_call_id": simulated_tool_call["id"],
                        "function_name": simulated_tool_call["function"]["name"],
                        "result": tool_result,
                        "success": True
                    },
                    trace_id=trace_id,
                    event_type=EventType.TOOL_RESULT
                )

                # Simulate final response using tool result
                final_response = f"The weather in San Francisco is {tool_result['temperature']}°F and {tool_result['conditions']}."

                trace_store.write_event(
                    {
                        "type": "model_response",
                        "content": final_response,
                        "model": "{{ model_name }}",
                        "used_tools": [simulated_tool_call["function"]["name"]]
                    },
                    trace_id=trace_id,
                    event_type=EventType.MODEL_RESPONSE
                )

                print(f"✅ Test passed: {{ agent_name }}")
                print(f"Tool called: {simulated_tool_call['function']['name']}")
                print(f"Final response: {final_response}")

            except Exception as e:
                trace_store.write_event(
                    {
                        "type": "error",
                        "error_message": str(e),
                        "error_type": type(e).__name__
                    },
                    trace_id=trace_id,
                    event_type=EventType.ERROR
                )
                raise

            finally:
                # End trace
                trace_store.end_trace(trace_id)


    if __name__ == "__main__":
        pytest.main([__file__, "-v", "-s"])

  requirements: |
    # Generated by TigerHill Template Library
    # Template: {{ metadata.name }}
    {% for dep in dependencies.pip -%}
    {{ dep }}
    {% endfor %}

  readme: |
    # {{ metadata.display_name }}

    {{ metadata.description }}

    ## Generated Configuration

    - **Agent Name**: `{{ agent_name }}`
    - **Model**: `{{ model_name }}`
    - **Number of Tools**: `{{ num_tools }}`
    - **Validation**: `{{ 'Enabled' if validate_tool_calls else 'Disabled' }}`

    ## Tool Definitions

    This test includes {{ num_tools }} tool definition(s):
    1. **get_weather** - Get current weather for a location
    2. **calculate** - Perform mathematical calculations
    3. **search** - Search for information

    ## Installation

    ```bash
    pip install -r requirements.txt
    ```

    ## Setup

    Set your API key:

    ```bash
    export OPENAI_API_KEY="your-openai-key"  # For GPT models
    export ANTHROPIC_API_KEY="your-anthropic-key"  # For Claude models
    ```

    ## Usage

    Run the test:

    ```bash
    pytest test_{{ agent_name }}.py -v -s
    ```

    ## Customization

    Replace the TODO section with actual LLM API calls:

    ```python
    import openai

    client = openai.OpenAI()
    response = client.chat.completions.create(
        model="{{ model_name }}",
        messages=[{"role": "user", "content": prompt}],
        tools=tool_definitions,
        tool_choice="auto"
    )

    # Extract tool calls from response
    tool_calls = response.choices[0].message.tool_calls
    ```

    ## Documentation

    For more information, see:
    - [TigerHill Documentation](https://github.com/yourusername/tigerhill)
    - [Function Calling Guide](https://platform.openai.com/docs/guides/function-calling)
