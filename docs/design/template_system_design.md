# Template System Design

## Overview

The Template Library provides pre-built, customizable test script templates for common testing scenarios. Users can quickly generate test scripts by selecting a template and providing parameters through an interactive CLI wizard.

## Design Goals

1. **Ease of Use**: Non-technical users can generate test scripts without writing code
2. **Flexibility**: Templates support parameterization and customization
3. **Extensibility**: Easy to add new templates
4. **Quality**: Templates follow best practices and include documentation
5. **Discovery**: Users can easily browse and search templates

## Template File Format

Templates are stored as YAML files with embedded Jinja2 templates for code generation.

### Template Structure

```yaml
# Template metadata
metadata:
  name: "http-api-test"
  display_name: "HTTP API Testing"
  description: "Test an HTTP API endpoint with request/response validation"
  category: "http"
  version: "1.0.0"
  author: "TigerHill"
  tags: ["http", "api", "rest", "validation"]

# Template parameters
parameters:
  - name: "agent_name"
    display_name: "Agent Name"
    description: "Name for the test agent"
    type: "string"
    required: true
    default: "my-api-agent"
    validation:
      pattern: "^[a-zA-Z0-9_-]+$"

  - name: "api_url"
    display_name: "API URL"
    description: "The API endpoint to test"
    type: "string"
    required: true
    validation:
      pattern: "^https?://.+"

  - name: "http_method"
    display_name: "HTTP Method"
    description: "HTTP method for the request"
    type: "choice"
    required: true
    default: "GET"
    choices: ["GET", "POST", "PUT", "DELETE", "PATCH"]

  - name: "expected_status"
    display_name: "Expected Status Code"
    description: "Expected HTTP status code"
    type: "integer"
    required: true
    default: 200
    validation:
      min: 100
      max: 599

  - name: "request_body"
    display_name: "Request Body"
    description: "JSON request body (for POST/PUT)"
    type: "json"
    required: false
    default: "{}"

  - name: "validate_response"
    display_name: "Validate Response"
    description: "Add response validation assertions"
    type: "boolean"
    required: true
    default: true

# Dependencies
dependencies:
  pip:
    - "requests>=2.31.0"
    - "pytest>=7.4.0"
  system: []

# Generated files
files:
  - path: "test_{{agent_name}}.py"
    template: "main_script"
  - path: "requirements.txt"
    template: "requirements"
  - path: "README.md"
    template: "readme"

# Code templates (Jinja2)
templates:
  main_script: |
    #!/usr/bin/env python3
    """
    {{ metadata.display_name }} - Generated by TigerHill

    {{ metadata.description }}
    """

    import pytest
    import requests
    from tigerhill.adapters.http_adapter import HTTPAdapter
    from tigerhill.assertions import (
        assert_http_status,
        assert_response_contains,
        assert_response_json_schema
    )
    from tigerhill.storage.trace_store import TraceStore


    class Test{{ agent_name | title | replace('-', '') | replace('_', '') }}:
        """{{ metadata.display_name }} Test Suite"""

        @pytest.fixture
        def adapter(self):
            """Create HTTP adapter"""
            return HTTPAdapter(
                base_url="{{ api_url }}",
                timeout=30
            )

        @pytest.fixture
        def trace_store(self, tmp_path):
            """Create trace store for recording"""
            return TraceStore(storage_path=str(tmp_path))

        def test_{{ agent_name | replace('-', '_') }}(self, adapter, trace_store):
            """Test {{ display_name }}"""

            # Start trace
            trace_id = trace_store.start_trace(
                agent_name="{{ agent_name }}",
                task_id="api-test-{{ agent_name }}",
                metadata={
                    "url": "{{ api_url }}",
                    "method": "{{ http_method }}"
                }
            )

            try:
                # Prepare request
                {% if http_method in ['POST', 'PUT', 'PATCH'] and request_body %}
                request_body = {{ request_body }}
                {% else %}
                request_body = None
                {% endif %}

                # Execute request
                response = adapter.execute(
                    trace_id=trace_id,
                    method="{{ http_method }}",
                    endpoint="/",
                    {% if request_body %}json=request_body,{% endif %}
                )

                {% if validate_response %}
                # Validate response
                assert_http_status(
                    response,
                    expected_status={{ expected_status }},
                    trace_id=trace_id
                )

                # Additional validations
                assert response.text, "Response body should not be empty"

                # Try to parse as JSON
                try:
                    json_data = response.json()
                    trace_store.write_event(
                        {
                            "type": "validation",
                            "message": "Response is valid JSON",
                            "data": json_data
                        },
                        trace_id=trace_id
                    )
                except ValueError:
                    trace_store.write_event(
                        {
                            "type": "info",
                            "message": "Response is not JSON format"
                        },
                        trace_id=trace_id
                    )
                {% endif %}

                print(f"✅ Test passed: {{ agent_name }}")

            except Exception as e:
                trace_store.write_event(
                    {
                        "type": "error",
                        "error_message": str(e),
                        "error_type": type(e).__name__
                    },
                    trace_id=trace_id
                )
                raise

            finally:
                # End trace
                trace_store.end_trace(trace_id)


    if __name__ == "__main__":
        pytest.main([__file__, "-v", "-s"])

  requirements: |
    # Generated by TigerHill Template Library
    # Template: {{ metadata.name }}

    {% for dep in dependencies.pip %}
    {{ dep }}
    {% endfor %}

  readme: |
    # {{ metadata.display_name }}

    {{ metadata.description }}

    ## Generated Configuration

    - **Agent Name**: {{ agent_name }}
    - **API URL**: {{ api_url }}
    - **HTTP Method**: {{ http_method }}
    - **Expected Status**: {{ expected_status }}

    ## Installation

    ```bash
    pip install -r requirements.txt
    ```

    ## Usage

    Run the test:

    ```bash
    pytest test_{{ agent_name }}.py -v
    ```

    ## Customization

    You can modify the generated test script to add:
    - More validation assertions
    - Custom headers
    - Authentication
    - Request/response logging

    ## Documentation

    For more information, see:
    - [TigerHill Documentation](https://github.com/yourusername/tigerhill)
    - [Assertions Reference](https://github.com/yourusername/tigerhill/docs/assertions.md)
```

## Template Categories

Templates are organized into categories for easy discovery:

### 1. **HTTP Testing** (`http/`)
- `http-api-test.yaml` - Basic HTTP API testing
- `http-rest-crud.yaml` - REST CRUD operations testing
- `http-auth-test.yaml` - Authentication testing
- `http-rate-limit.yaml` - Rate limiting testing

### 2. **CLI Testing** (`cli/`)
- `cli-basic.yaml` - Basic CLI agent testing
- `cli-interactive.yaml` - Interactive CLI testing
- `cli-streaming.yaml` - Streaming output testing

### 3. **STDIO Testing** (`stdio/`)
- `stdio-basic.yaml` - Basic STDIO protocol testing
- `stdio-json-rpc.yaml` - JSON-RPC protocol testing

### 4. **LLM Testing** (`llm/`)
- `llm-prompt-response.yaml` - Basic prompt/response testing
- `llm-multi-turn.yaml` - Multi-turn conversation testing
- `llm-function-calling.yaml` - Function calling testing
- `llm-cost-validation.yaml` - Cost and token validation

### 5. **Integration Testing** (`integration/`)
- `integration-e2e.yaml` - End-to-end integration testing
- `integration-pipeline.yaml` - Multi-step pipeline testing

## Parameter Types

The template system supports various parameter types:

| Type | Description | Validation |
|------|-------------|------------|
| `string` | Text input | pattern, min_length, max_length |
| `integer` | Numeric input | min, max |
| `float` | Decimal input | min, max |
| `boolean` | True/False | - |
| `choice` | Select from options | choices list |
| `json` | JSON object | valid JSON |
| `url` | URL input | URL pattern |
| `email` | Email input | Email pattern |
| `path` | File/directory path | exists check |

## Directory Structure

```
tigerhill/
├── templates/
│   ├── catalog.yaml           # Template catalog index
│   ├── http/
│   │   ├── http-api-test.yaml
│   │   ├── http-rest-crud.yaml
│   │   └── http-auth-test.yaml
│   ├── cli/
│   │   ├── cli-basic.yaml
│   │   └── cli-interactive.yaml
│   ├── stdio/
│   │   ├── stdio-basic.yaml
│   │   └── stdio-json-rpc.yaml
│   ├── llm/
│   │   ├── llm-prompt-response.yaml
│   │   ├── llm-multi-turn.yaml
│   │   └── llm-function-calling.yaml
│   └── integration/
│       └── integration-e2e.yaml
├── tigerhill/
│   └── template_engine/
│       ├── __init__.py
│       ├── loader.py          # Load and parse templates
│       ├── validator.py       # Validate parameters
│       ├── generator.py       # Generate code from templates
│       ├── catalog.py         # Template catalog management
│       └── cli.py             # CLI wizard tool
└── tests/
    └── test_template_engine/
        ├── test_loader.py
        ├── test_validator.py
        ├── test_generator.py
        └── test_cli.py
```

## Template Catalog

The catalog provides an index of all available templates:

```yaml
# templates/catalog.yaml
version: "1.0.0"
last_updated: "2024-01-15"

categories:
  http:
    name: "HTTP Testing"
    description: "Templates for testing HTTP APIs and services"
    templates:
      - http-api-test
      - http-rest-crud
      - http-auth-test
      - http-rate-limit

  cli:
    name: "CLI Testing"
    description: "Templates for testing command-line agents"
    templates:
      - cli-basic
      - cli-interactive
      - cli-streaming

  # ... more categories

templates:
  http-api-test:
    path: "http/http-api-test.yaml"
    name: "HTTP API Testing"
    description: "Test an HTTP API endpoint"
    difficulty: "beginner"
    estimated_time: "5 minutes"

  # ... more templates
```

## Template Engine API

### Loading Templates

```python
from tigerhill.template_engine import TemplateLoader

loader = TemplateLoader()

# Load single template
template = loader.load_template("http/http-api-test.yaml")

# List all templates
all_templates = loader.list_templates()

# Search templates
api_templates = loader.search_templates(category="http", tags=["api"])
```

### Validating Parameters

```python
from tigerhill.template_engine import TemplateValidator

validator = TemplateValidator(template)

# Validate parameters
params = {
    "agent_name": "my-api-agent",
    "api_url": "https://api.example.com",
    "http_method": "GET",
    "expected_status": 200
}

is_valid, errors = validator.validate(params)
if not is_valid:
    print(f"Validation errors: {errors}")
```

### Generating Code

```python
from tigerhill.template_engine import CodeGenerator

generator = CodeGenerator(template)

# Generate files
output_dir = "./generated_tests"
generator.generate(params, output_dir=output_dir)

# Generated files:
# ./generated_tests/test_my_api_agent.py
# ./generated_tests/requirements.txt
# ./generated_tests/README.md
```

## CLI Wizard

Interactive command-line tool for template-based test generation:

```bash
# Launch wizard
tigerhill create-test

# Or with template specified
tigerhill create-test --template http-api-test

# Non-interactive mode
tigerhill create-test --template http-api-test \
  --param agent_name=my-api \
  --param api_url=https://api.example.com \
  --param http_method=GET \
  --output ./tests/
```

### Wizard Flow

```
┌─────────────────────────────────────────┐
│  TigerHill Test Generator               │
│  Create test scripts from templates    │
└─────────────────────────────────────────┘

? Select template category:
  › HTTP Testing
    CLI Testing
    STDIO Testing
    LLM Testing
    Integration Testing

? Select template:
  › HTTP API Testing - Test an HTTP API endpoint
    REST CRUD Testing - Test REST CRUD operations
    Authentication Testing - Test API authentication
    Rate Limiting - Test rate limiting behavior

Template: HTTP API Testing
Test an HTTP API endpoint with request/response validation

┌─────────────────────────────────────────┐
│  Configure Parameters                   │
└─────────────────────────────────────────┘

? Agent Name (my-api-agent): my-weather-api
? API URL: https://api.weather.com/v1/current
? HTTP Method:
  › GET
    POST
    PUT
    DELETE
    PATCH
? Expected Status Code (200): 200
? Request Body (optional):
? Validate Response (Y/n): y

┌─────────────────────────────────────────┐
│  Review Configuration                   │
└─────────────────────────────────────────┘

Agent Name:         my-weather-api
API URL:            https://api.weather.com/v1/current
HTTP Method:        GET
Expected Status:    200
Validate Response:  Yes

? Output directory (./tests/): ./tests/weather/

? Generate test files? (Y/n): y

✅ Generated files:
   ./tests/weather/test_my_weather_api.py
   ./tests/weather/requirements.txt
   ./tests/weather/README.md

Next steps:
1. Install dependencies: cd ./tests/weather && pip install -r requirements.txt
2. Run tests: pytest test_my_weather_api.py -v
3. Customize the generated script as needed
```

## Implementation Phases

### Phase 1: Core Template Engine (2 hours)
- Template loader
- Parameter validator
- Code generator
- Basic error handling

### Phase 2: Template Library (3 hours)
- Create 10+ templates across all categories
- Template catalog
- Documentation for each template

### Phase 3: CLI Wizard (2 hours)
- Interactive CLI with prompts
- Template browser
- Parameter collection
- File generation

### Phase 4: Testing & Documentation (2 hours)
- Unit tests for all components
- Integration tests
- User documentation
- Example usage

## Success Metrics

1. **Usability**: Users can generate a working test in <5 minutes
2. **Coverage**: 10+ templates covering common scenarios
3. **Quality**: Generated code passes all tests
4. **Adoption**: Templates used in >50% of new test creation

## Future Enhancements

1. **Custom Templates**: Users can create and share their own templates
2. **Template Marketplace**: Community template repository
3. **AI-Powered Generation**: Use LLM to suggest templates and parameters
4. **Visual Editor**: Web-based template editor
5. **Template Versioning**: Support multiple versions of templates
6. **Template Testing**: Automated testing of templates themselves
