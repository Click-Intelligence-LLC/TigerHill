"""
TigerHill Observer SDK - Python Basic Example

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ TigerHill Observer SDK æ•èŽ· Google Generative AI çš„ prompt å’Œå“åº”ã€‚

ä½¿ç”¨æ­¥éª¤ï¼š
1. å®‰è£…ä¾èµ–: pip install google-generativeai
2. è®¾ç½®çŽ¯å¢ƒå˜é‡: export GOOGLE_API_KEY=your_api_key
3. è¿è¡Œ: python examples/observer_python_basic.py
"""

import os
from tigerhill.observer import PromptCapture, wrap_python_model
from tigerhill.observer.python_observer import create_observer_callback

try:
    import google.generativeai as genai
except ImportError:
    print("Error: Please install google-generativeai: pip install google-generativeai")
    exit(1)


def main():
    # æ£€æŸ¥ API key
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("Error: Please set GOOGLE_API_KEY environment variable")
        print("Example: export GOOGLE_API_KEY=your_api_key")
        exit(1)

    # é…ç½® API
    genai.configure(api_key=api_key)

    # 1. åˆ›å»ºæ•èŽ·å™¨
    capture = PromptCapture(
        storage_path="./prompt_captures",
        auto_save=True  # è‡ªåŠ¨ä¿å­˜åˆ°æ–‡ä»¶
    )

    # 2. å¼€å§‹æ•èŽ·ä¼šè¯
    capture_id = capture.start_capture(
        agent_name="code_assistant",
        metadata={
            "task": "generate_fibonacci",
            "version": "1.0"
        }
    )

    print(f"ðŸŽ¯ Started capture session: {capture_id}")

    # 3. åˆ›å»ºè§‚å¯Ÿå›žè°ƒ
    callback = create_observer_callback(capture, capture_id)

    # 4. åŒ…è£… GenerativeModel
    WrappedModel = wrap_python_model(
        genai.GenerativeModel,
        capture_callback=callback,
        capture_response=True
    )

    # 5. ä½¿ç”¨åŒ…è£…åŽçš„æ¨¡åž‹
    print("\nðŸ“ Creating model and generating content...")

    # å°è¯•ä¸åŒçš„æ¨¡åž‹åç§°ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
    model_names = [
        "gemini-2.5-flash",     # æœ€æ–°ç‰ˆæœ¬ï¼ˆä¼˜å…ˆï¼‰
        "gemini-2.0-flash-exp", # Gemini 2.0 å®žéªŒç‰ˆæœ¬
        "gemini-1.5-flash",     # 1.5 Flash
        "gemini-pro",           # ç¨³å®šç‰ˆæœ¬
        "gemini-1.0-pro",       # æ—§ç‰ˆæœ¬
    ]

    model = None
    for model_name in model_names:
        try:
            print(f"   Trying model: {model_name}...")
            model = WrappedModel(model_name)
            print(f"   âœ… Successfully created model: {model_name}")
            break
        except Exception as e:
            print(f"   âŒ Failed: {str(e)[:80]}")
            continue

    if model is None:
        print("\nâŒ Error: Could not create any model.")
        print("Please check:")
        print("  1. GOOGLE_API_KEY is set correctly")
        print("  2. API key has access to Gemini models")
        print("  3. Run: gcloud auth application-default login")
        exit(1)

    # ç¬¬ä¸€ä¸ªè¯·æ±‚
    print("\n[Request 1] Asking for fibonacci function...")
    response1 = model.generate_content("Write a Python function to calculate fibonacci numbers")
    print(f"âœ… Response 1 received: {len(response1.text)} characters")

    # ç¬¬äºŒä¸ªè¯·æ±‚
    print("\n[Request 2] Asking for optimization...")
    response2 = model.generate_content("Can you optimize the fibonacci function with memoization?")
    print(f"âœ… Response 2 received: {len(response2.text)} characters")

    # 6. ç»“æŸæ•èŽ·
    print("\nðŸ“Š Ending capture session...")
    result = capture.end_capture(capture_id)

    # 7. æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 60)
    print("ðŸ“ˆ Capture Statistics:")
    print("=" * 60)
    print(f"Agent: {result['agent_name']}")
    print(f"Duration: {result['duration']:.2f} seconds")
    print(f"Total Requests: {result['statistics']['total_requests']}")
    print(f"Total Responses: {result['statistics']['total_responses']}")
    print(f"Total Tokens: {result['statistics']['total_tokens']:,}")
    print(f"  - Prompt Tokens: {result['statistics']['total_prompt_tokens']:,}")
    print(f"  - Completion Tokens: {result['statistics']['total_completion_tokens']:,}")

    if result['statistics']['total_tokens'] > 0:
        avg_tokens = result['statistics']['total_tokens'] / result['statistics']['total_requests']
        print(f"Average Tokens per Request: {avg_tokens:.0f}")

    print("=" * 60)
    print(f"\nâœ… Capture saved to: ./prompt_captures/capture_{capture_id}_*.json")
    print("\nðŸ’¡ Next steps:")
    print("   - Use PromptAnalyzer to analyze the captured data")
    print("   - Export to TraceStore for integration with TigerHill testing")
    print("   - Review and optimize your prompts based on captured data")


if __name__ == "__main__":
    main()
