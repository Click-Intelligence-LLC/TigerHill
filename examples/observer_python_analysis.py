"""
TigerHill Observer SDK - Python Analysis Example

ÊºîÁ§∫Â¶Ç‰Ωï‰ΩøÁî® PromptAnalyzer Ëá™Âä®ÂàÜÊûêÊçïËé∑ÁöÑÊï∞ÊçÆÔºåËé∑Âèñ‰ºòÂåñÂª∫ËÆÆ„ÄÇ

‰ΩøÁî®Ê≠•È™§Ôºö
1. ÂÖàËøêË°å observer_python_basic.py ÁîüÊàêÊçïËé∑Êï∞ÊçÆ
2. ËøêË°å: python examples/observer_python_analysis.py
"""

import json
from pathlib import Path
from tigerhill.observer import PromptCapture, PromptAnalyzer


def load_latest_capture(storage_path="./prompt_captures"):
    """Âä†ËΩΩÊúÄÊñ∞ÁöÑÊçïËé∑Êñá‰ª∂"""
    capture_dir = Path(storage_path)
    if not capture_dir.exists():
        print(f"Error: {storage_path} does not exist")
        print("Please run observer_python_basic.py first to generate capture data")
        return None

    # Êü•ÊâæÊâÄÊúâÊçïËé∑Êñá‰ª∂
    capture_files = list(capture_dir.glob("capture_*.json"))
    if not capture_files:
        print(f"Error: No capture files found in {storage_path}")
        print("Please run observer_python_basic.py first to generate capture data")
        return None

    # Ëé∑ÂèñÊúÄÊñ∞ÁöÑÊñá‰ª∂
    latest_file = max(capture_files, key=lambda p: p.stat().st_mtime)
    print(f"üìÇ Loading capture from: {latest_file}")

    with open(latest_file, "r", encoding="utf-8") as f:
        return json.load(f)


def main():
    # 1. Âä†ËΩΩÊçïËé∑Êï∞ÊçÆ
    capture_data = load_latest_capture()
    if not capture_data:
        return

    print(f"\n‚úÖ Loaded capture: {capture_data['capture_id']}")
    print(f"   Agent: {capture_data['agent_name']}")
    print(f"   Requests: {len(capture_data['requests'])}")
    print(f"   Responses: {len(capture_data['responses'])}")

    # 2. ÂàõÂª∫ÂàÜÊûêÂô®
    print("\nüîç Creating analyzer...")
    analyzer = PromptAnalyzer(capture_data)

    # 3. ÊâßË°åÂÆåÊï¥ÂàÜÊûê
    print("\nüìä Analyzing captured data...")
    report = analyzer.analyze_all()

    # 4. ÊâìÂç∞Êä•Âëä
    analyzer.print_report(report)

    # 5. ËØ¶ÁªÜÂ±ïÁ§∫Âª∫ËÆÆ
    if report["recommendations"]:
        print("\n" + "=" * 80)
        print("üí° Detailed Recommendations:")
        print("=" * 80)

        for i, rec in enumerate(report["recommendations"], 1):
            severity_emoji = {"high": "üî¥", "medium": "üü°", "low": "üü¢"}.get(rec["severity"], "‚ö™")
            print(f"\n[{i}] {severity_emoji} {rec['title']} ({rec['category']})")
            print(f"    Severity: {rec['severity'].upper()}")
            print(f"    Description: {rec['description']}")
            print(f"    Suggestion: {rec['suggestion']}")
    else:
        print("\n‚úÖ No issues detected! Your prompts look good.")

    # 6. ‰øùÂ≠òÂàÜÊûêÊä•Âëä
    report_file = f"./prompt_captures/analysis_{capture_data['capture_id']}.json"
    with open(report_file, "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    print(f"\nüìÑ Analysis report saved to: {report_file}")

    # 7. Êèê‰æõÊìç‰ΩúÂª∫ËÆÆ
    print("\n" + "=" * 80)
    print("üéØ Action Items:")
    print("=" * 80)

    # Token ‰ºòÂåñÂª∫ËÆÆ
    token_analysis = report["token_analysis"]
    if token_analysis["avg_prompt_tokens"] > 2000:
        print("1. ‚ö†Ô∏è  Reduce prompt length to save costs")
        print("   - Current avg: {:.0f} tokens".format(token_analysis["avg_prompt_tokens"]))
        print("   - Target: < 2000 tokens")

    if token_analysis["token_efficiency_ratio"] < 0.5:
        print("2. ‚ö†Ô∏è  Improve token efficiency")
        print("   - Current ratio: {:.2f}".format(token_analysis["token_efficiency_ratio"]))
        print("   - Consider requesting more detailed outputs")

    # Ë¥®ÈáèÂª∫ËÆÆ
    quality = report["prompt_quality"]
    if quality["has_system_prompt_ratio"] < 0.8:
        print("3. ‚ö†Ô∏è  Add system prompts for better control")
        print("   - Current: {:.0f}% of requests have system prompt".format(
            quality["has_system_prompt_ratio"] * 100
        ))
        print("   - Target: > 80%")

    if quality["clarity_score"] < 0.7:
        print("4. ‚ö†Ô∏è  Improve prompt clarity")
        print("   - Current score: {:.2f}/1.0".format(quality["clarity_score"]))
        print("   - Add specific instructions and examples")

    # Â∑•ÂÖ∑‰ΩøÁî®Âª∫ËÆÆ
    tool_usage = report["tool_usage"]
    if tool_usage["tools_defined_but_not_used"]:
        print("5. üí° Remove unused tools:")
        for tool in tool_usage["tools_defined_but_not_used"][:3]:
            print(f"   - {tool}")

    # ÊÄßËÉΩÂª∫ËÆÆ
    performance = report["performance"]
    if performance["avg_duration"] > 10:
        print("6. ‚ö†Ô∏è  Optimize response time")
        print("   - Current avg: {:.2f}s".format(performance["avg_duration"]))
        print("   - Consider using faster models or simpler prompts")

    print("\n" + "=" * 80)
    print("‚ú® Analysis complete! Use these insights to optimize your prompts.")
    print("=" * 80)


if __name__ == "__main__":
    main()
