/**
 * TigerHill Observer SDK - Node.js Basic Example
 *
 * ÊºîÁ§∫Â¶Ç‰Ωï‰ΩøÁî® TigerHill Observer SDK ÊçïËé∑ Google Generative AI ÁöÑ prompt ÂíåÂìçÂ∫î„ÄÇ
 *
 * ‰ΩøÁî®Ê≠•È™§Ôºö
 * 1. ÂÆâË£Ö‰æùËµñ: npm install @google/generative-ai
 * 2. ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáè: export GOOGLE_API_KEY=your_api_key
 * 3. ËøêË°å: node examples/observer_nodejs_basic.js
 */

const { GoogleGenerativeAI } = require('@google/generative-ai');
const { wrapGenerativeModel } = require('../tigerhill/observer/node_observer');

async function main() {
    // Ê£ÄÊü• API key
    const apiKey = process.env.GOOGLE_API_KEY;
    if (!apiKey) {
        console.error('Error: Please set GOOGLE_API_KEY environment variable');
        console.error('Example: export GOOGLE_API_KEY=your_api_key');
        process.exit(1);
    }

    console.log('='.repeat(80));
    console.log('üöÄ TigerHill Observer SDK - Node.js Example');
    console.log('='.repeat(80));

    // 1. ÂåÖË£Ö GoogleGenerativeAI
    console.log('\n[Step 1] Wrapping GenerativeModel...');

    const capturedData = {
        requests: [],
        responses: []
    };

    const WrappedModel = wrapGenerativeModel(
        require('@google/generative-ai').GoogleGenerativeAI.prototype.constructor,
        {
            // ËØ∑Ê±ÇÂõûË∞É
            onRequest: (data) => {
                console.log(`\nüì§ Request captured:`);
                console.log(`   Model: ${data.model}`);
                console.log(`   Prompt: ${JSON.stringify(data.prompt).substring(0, 80)}...`);
                capturedData.requests.push(data);
            },

            // ÂìçÂ∫îÂõûË∞É
            onResponse: (data) => {
                console.log(`\nüì• Response captured:`);
                console.log(`   Text length: ${data.text?.length || 0} characters`);
                if (data.usage) {
                    console.log(`   Tokens: ${data.usage.total_tokens} (prompt: ${data.usage.prompt_tokens}, completion: ${data.usage.completion_tokens})`);
                }
                capturedData.responses.push(data);
            },

            // Ëá™Âä®ÂØºÂá∫ÈÖçÁΩÆ
            autoExport: true,
            exportPath: './prompt_captures',

            // ÂèØÈÄâÔºöÂèëÈÄÅÂà∞ TigerHill ÊúçÂä°Âô®
            // captureEndpoint: 'http://localhost:8000/api/capture'
        }
    );

    // 2. ÂàõÂª∫ AI ÂÆû‰æã
    console.log('\n[Step 2] Creating AI instance...');
    const genAI = new GoogleGenerativeAI(apiKey);

    // Ê≥®ÊÑèÔºöÁî±‰∫é Node.js SDK ÁöÑÈôêÂà∂ÔºåÊàë‰ª¨ÈúÄË¶ÅÊâãÂä®ÂåÖË£ÖÊ®°ÂûãÂÆû‰æã
    // ËøôÈáåÊàë‰ª¨‰ΩøÁî®Âü∫Á°ÄÊ®°ÂûãËøõË°åÊºîÁ§∫
    const model = genAI.getGenerativeModel({ model: 'gemini-2.5-flash' });

    console.log('‚úÖ Model created: gemini-2.5-flash');

    // 3. ‰ΩøÁî®Ê®°ÂûãÁîüÊàêÂÜÖÂÆπ
    console.log('\n[Step 3] Generating content...');

    // Á¨¨‰∏Ä‰∏™ËØ∑Ê±Ç
    console.log('\n--- Request 1: Fibonacci Function ---');
    const prompt1 = 'Write a Python function to calculate fibonacci numbers';
    const result1 = await model.generateContent(prompt1);
    const response1 = await result1.response;
    const text1 = response1.text();

    console.log(`‚úÖ Response received: ${text1.length} characters`);
    console.log(`   Preview: ${text1.substring(0, 100)}...`);

    // Á¨¨‰∫å‰∏™ËØ∑Ê±Ç
    console.log('\n--- Request 2: Optimization ---');
    const prompt2 = 'Can you optimize the fibonacci function with memoization?';
    const result2 = await model.generateContent(prompt2);
    const response2 = await result2.response;
    const text2 = response2.text();

    console.log(`‚úÖ Response received: ${text2.length} characters`);
    console.log(`   Preview: ${text2.substring(0, 100)}...`);

    // 4. ÊòæÁ§∫ÁªüËÆ°‰ø°ÊÅØ
    console.log('\n' + '='.repeat(80));
    console.log('üìä Capture Statistics:');
    console.log('='.repeat(80));
    console.log(`Total Requests: ${capturedData.requests.length}`);
    console.log(`Total Responses: ${capturedData.responses.length}`);

    let totalTokens = 0;
    let totalPromptTokens = 0;
    let totalCompletionTokens = 0;

    capturedData.responses.forEach(resp => {
        if (resp.usage) {
            totalTokens += resp.usage.total_tokens || 0;
            totalPromptTokens += resp.usage.prompt_tokens || 0;
            totalCompletionTokens += resp.usage.completion_tokens || 0;
        }
    });

    console.log(`Total Tokens: ${totalTokens.toLocaleString()}`);
    console.log(`  - Prompt Tokens: ${totalPromptTokens.toLocaleString()}`);
    console.log(`  - Completion Tokens: ${totalCompletionTokens.toLocaleString()}`);

    if (capturedData.requests.length > 0) {
        console.log(`Average Tokens per Request: ${(totalTokens / capturedData.requests.length).toFixed(0)}`);
    }

    console.log('='.repeat(80));

    // 5. ‰ΩøÁî®ÊèêÁ§∫
    console.log('\nüí° Next Steps:');
    console.log('   1. Check ./prompt_captures/ for exported JSON files');
    console.log('   2. Use Python PromptAnalyzer to analyze the data:');
    console.log('      python examples/observer_python_analysis.py');
    console.log('   3. Export to TraceStore for testing:');
    console.log('      python examples/observer_tracestore_integration.py');
    console.log('   4. Integrate with your CI/CD pipeline');

    console.log('\n‚úÖ Example completed successfully!');
}

// ÈîôËØØÂ§ÑÁêÜ
main().catch(error => {
    console.error('\n‚ùå Error:', error.message);
    console.error(error.stack);
    process.exit(1);
});


/**
 * Alternative: Using Auto-Instrumentation with Shim
 *
 * For automatic instrumentation without manual wrapping:
 *
 * 1. Create shim file:
 *    const { createShim } = require('./tigerhill/observer/node_observer');
 *    createShim('./tigerhill-shim.js');
 *
 * 2. Use shim:
 *    NODE_OPTIONS="--require ./tigerhill-shim.js" node your_script.js
 *
 * This will automatically instrument all @google/generative-ai imports.
 */
